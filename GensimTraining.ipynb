{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GensimTraining.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMJ+8w3XdDHPloEUag2uPZC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harikrishnareddymallavarapu/DeepAndNLP/blob/master/GensimTraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRs8s_bSoQcJ"
      },
      "source": [
        "import gensim\n",
        "from gensim import corpora\n",
        "from pprint import pprint\n",
        "import itertools as it"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhK0pHv7ocF9"
      },
      "source": [
        "#Gensim Introduction\n",
        "\n",
        "- Gensim requires every word to be mappeed to a unique id, to do this gensim creates a Dictionary object to map word to unique id\n",
        "- To achieve this, we have to convert text / sentences to [list of words] and pass it to the corpora.Dictionary() object\n",
        "- Dictionary is typically used to create 'Bag of Words' corpus\n",
        "- When text files are large, Gensim lets us to update the dictionary one line at a time without loading the entire text file into the memory\n",
        "\n",
        "- Dictionary is a map of all words to its unique id"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ce3iblXQoUzw"
      },
      "source": [
        "documents = [\"The Saudis are preparing a report that will acknowledge that\", \n",
        "             \"Saudi journalist Jamal Khashoggi's death was the result of an\", \n",
        "             \"to his abduction from Turkey, according to two sources.\"]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SdZQnxzoix1"
      },
      "source": [
        "###Breaking sentences to words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ch_paUF6ofXL"
      },
      "source": [
        "text = [ [text for text in doc.split()] for doc in documents]\n",
        "print(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdKvUdJFpGmv"
      },
      "source": [
        "#Breaks sentence in characters\n",
        "text1 = list(it.chain(documents[0]))\n",
        "text1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEF_C2Jfp7hR"
      },
      "source": [
        "###Creating Dictionary object using Corpora"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6jycvr8p6ks",
        "outputId": "7cac3d56-4220-4df3-83de-1f06ff1b3ffe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "dictionary = corpora.Dictionary(text)\n",
        "print(dictionary)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<gensim.corpora.dictionary.Dictionary object at 0x7fcf73d9bb38>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8Pu2eHKqaQl"
      },
      "source": [
        "#Checking for token id and word\n",
        "print(dictionary.token2id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR9P20WRq9lv"
      },
      "source": [
        "###Extending dictionary object with new documents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S6cIocdrHlI"
      },
      "source": [
        "documents_2 = [\"The intersection graph of paths in trees\",\n",
        "               \"Graph minors IV Widths of trees and well quasi ordering\",\n",
        "               \"Graph minors A survey\"]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZVP3hVFrKgm"
      },
      "source": [
        "text2 = [[text for text in doc.split()] for doc in documents_2]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1iPyaGWrSmH"
      },
      "source": [
        "dictionary.add_documents(text2)\n",
        "print(dictionary)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UxVtQYsrewg"
      },
      "source": [
        "###Loading Large file, Here we load the files line by line without loading the entire corpus into the memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oluCO-Nzrxod"
      },
      "source": [
        "from gensim.utils import simple_preprocess\n",
        "from smart_open import smart_open\n",
        "import os"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0jbvbJTsKvt",
        "outputId": "43d9d233-f634-4f62-c8ba-047ed8800667",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "simple_preprocess(documents[0],deacc=True)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the',\n",
              " 'saudis',\n",
              " 'are',\n",
              " 'preparing',\n",
              " 'report',\n",
              " 'that',\n",
              " 'will',\n",
              " 'acknowledge',\n",
              " 'that']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiEGO5EEr5ra"
      },
      "source": [
        "dictionary = corpora.Dictionary(simple_preprocess(line, deacc=True) for line in open('sample.txt', encoding='utf-8'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j96Y9s13sGC6"
      },
      "source": [
        "dictionary.token2id"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m31BCOm0sXfj"
      },
      "source": [
        "###Creating Corpora from multiple files without loading into the memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhoXGQFcsf2h"
      },
      "source": [
        "class ReadTxtFiles(object):\n",
        "    def __init__(self, dirname):\n",
        "        self.dirname = dirname\n",
        "\n",
        "    def __iter__(self):\n",
        "        for fname in os.listdir(self.dirname):\n",
        "            for line in open(os.path.join(self.dirname, fname), encoding='latin'):\n",
        "                yield simple_preprocess(line)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eE2JQvBys1rY"
      },
      "source": [
        "path_to_text_directory = \"driveFolder\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHBV-4FLszh4"
      },
      "source": [
        "dictionary = corpora.Dictionary(ReadTxtFiles(path_to_text_directory))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vmc9F_7LqLWI"
      },
      "source": [
        "###Creating Bag of words using the dictionary, words are replaced with their ids\n",
        "- Its equivalent to Document Term Matrix\n",
        "- Need to know why cant the dictioanry object used directly to create BOW\n",
        "- the output is a tuple that contains the id of the word and its frequency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJMc23cttTMP"
      },
      "source": [
        "tokenized_list = [simple_preprocess(doc) for doc in documents]\n",
        "tokenized_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV9t327SuEcC",
        "outputId": "4a2d3702-286e-45d1-8293-a83e4701290f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "dictionaryObj = corpora.Dictionary()\n",
        "bowText = [dictionaryObj.doc2bow(doc, allow_update = True) for doc in tokenized_list]\n",
        "pprint(bowText)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2), (6, 1), (7, 1)],\n",
            " [(6, 1),\n",
            "  (8, 1),\n",
            "  (9, 1),\n",
            "  (10, 1),\n",
            "  (11, 1),\n",
            "  (12, 1),\n",
            "  (13, 1),\n",
            "  (14, 1),\n",
            "  (15, 1),\n",
            "  (16, 1)],\n",
            " [(17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 2), (23, 1), (24, 1)]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phxTnVdOuph2",
        "outputId": "8d0b4fb3-6c8a-413a-99e0-2721f3a55ca1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "print(bowText[0])\n",
        "print(\"**\")\n",
        "print(bowText[0][0])\n",
        "print(\"**\")\n",
        "print(type(bowText[0][0]))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2), (6, 1), (7, 1)]\n",
            "'**'\n",
            "(0, 1)\n",
            "'**'\n",
            "<class 'tuple'>\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}